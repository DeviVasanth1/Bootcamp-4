âš™ï¸ Prerequisites
Ensure the following are done before running the project:

Python 3.8+

Google Cloud SDK installed and authenticated

Enable APIs:

Pub/Sub

Dataflow

BigQuery

Cloud Storage
---------------------------------
# Set environment variables
export PROJECT_ID=devi-bootcamp
export REGION=us-central1
export BUCKET_NAME=devi-bootcamp-temp-bucket
export TOPIC_NAME=fraud-transactions-topic

# Create Cloud Storage bucket
gcloud storage buckets create gs://$BUCKET_NAME --location=$REGION

# Create Pub/Sub topic
gcloud pubsub topics create $TOPIC_NAME

# Create BigQuery dataset
bq mk fraud_detection
------------------------------------------------------------
ğŸ“¤ Step 1: Publish Sample Transactions
python publisher.py
âœ… Sends sample transactions (some fraudulent) to your Pub/Sub topic.
ğŸ§ª Step 2: Deploy Apache Beam Pipeline to Dataflow
python pipeline.py \
  --input_topic=projects/devi-bootcamp/topics/fraud-transactions-topic \
  --output_table=devi-bootcamp:fraud_detection.flagged_transactions \
  --project=devi-bootcamp \
  --region=us-central1 \
  --temp_location=gs://devi-bootcamp-temp-bucket/temp \
  --runner=DataflowRunner
âœ… A streaming Dataflow job is started to process the transactions.
âœ… Step 3: Verify Dataflow is Running
Check job status: Running
Logs show messages like:
Running job using Streaming Engine
All workers have finished the startup processes and began to receive work requests.
ğŸ” Step 4: Query Flagged Transactions in BigQuery
bq query --use_legacy_sql=false '
SELECT transaction_id, user_id, amount, country, ip, timestamp
FROM `devi-bootcamp.fraud_detection.flagged_transactions`
ORDER BY timestamp DESC
LIMIT 10'
âœ… Returns latest flagged fraudulent transactions.
ğŸ“¦ Step 5: Export to CSV in Cloud Storage
# Create export bucket
gsutil mb -l us-central1 gs://devi-bootcamp-exports

# Export from BigQuery to CSV
bq extract \
  --destination_format=CSV \
  'devi-bootcamp.fraud_detection.flagged_transactions' \
  gs://devi-bootcamp-exports/flagged_transactions.csv
# Create export bucket
gsutil mb -l us-central1 gs://devi-bootcamp-exports

# Export from BigQuery to CSV
bq extract \
  --destination_format=CSV \
  'devi-bootcamp.fraud_detection.flagged_transactions' \
  gs://devi-bootcamp-exports/flagged_transactions.csv
âœ… A CSV file is saved in the devi-bootcamp-exports bucket.



# Real-Time Fraud Detection with Apache Beam and Google Cloud

## ğŸš€ Overview

This project demonstrates a real-time fraud detection pipeline using:

- **Cloud Pub/Sub** (for real-time transaction ingestion)
- **Cloud Dataflow** (Apache Beam pipeline for processing)
- **BigQuery** (for storing flagged fraud transactions)
- **Cloud Storage** (for staging/temporary data)

---

## âœ… Project Setup Summary

### ğŸ”§ Project & Tools Used

- **Project ID:** `devi-bootcamp`
- **Service Account:** `joyuslearn@gmail.com`
- **Region:** `us-central1`
- **Environment:** Local development + Cloud deployment

---

## ğŸ“¦ 1. Resources Created

### âœ… Pub/Sub

- **Topic:** `fraud-transactions-topic`
- **Purpose:** Receives transaction messages in JSON format

### âœ… Cloud Storage Buckets

- **Temp bucket:** `gs://devi-bootcamp-temp-bucket`
- **Clean data bucket (optional):** `gs://devi-bootcamp-clean-data`

```bash
gcloud storage buckets create gs://devi-bootcamp-temp-bucket --location=us-central1






âœ… BigQuery
Dataset: fraud_detection

Table: flagged_transactions

bq mk fraud_detection

bq mk -t fraud_detection.flagged_transactions \
transaction_id:STRING,user_id:STRING,amount:FLOAT,country:STRING,ip:STRING,timestamp:TIMESTAMP,fraud_reason:STRING
---------------------------------
ğŸ’¡ 2. Fraud Detection Logic
Fraud is flagged based on:

High transaction amount (> 1000)

Risky countries (Nigeria, Russia, etc.)

------------------------------------------

ğŸ§  3. Apache Beam (Dataflow) Pipeline
File: pipeline.py
Purpose:

Read from Pub/Sub

Filter suspicious transactions

Output flagged data to BigQuery

------------------------------------------
python pipeline.py \
  --input_topic=projects/devi-bootcamp/topics/fraud-transactions-topic \
  --output_table=devi-bootcamp:fraud_detection.flagged_transactions \
  --project=devi-bootcamp \
  --region=us-central1 \
  --temp_location=gs://devi-bootcamp-temp-bucket/temp
-------------------------------------------------------------

ğŸ“¨ 4. Publisher Script
File: publisher.py
Used to simulate transaction data into Pub/Sub.

---------------------------------------------------------

python publisher.py

--------------------------------------

--------------------------------------------------------------
ğŸ“Œ Next Steps (Tomorrow)


Steps
ğŸ” 5. Monitor & Verify
Dataflow UI: https://console.cloud.google.com/dataflow

BigQuery UI: https://console.cloud.google.com/bigquery

Verify data in BigQuery table

Test with more fraud scenarios

Add visualization (e.g., Looker Studio)

Optional: Add logging, monitoring, and dashboards
-------------------------------------------------------------

Check File/
â”œâ”€â”€ pipeline.py
â”œâ”€â”€ publisher.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
-----------------------------------------
{
  "transaction_id": "txn001",
  "user_id": "user001",
  "amount": 1500,
  "country": "Nigeria",
  "ip": "192.168.1.1",
  "timestamp": "2025-07-18T12:00:00Z"
}










